{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03053bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(26)\n",
    "n = 700\n",
    "internexp= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "friends_num= np.random.gamma(1, 30, n)\n",
    "family_reserve = np.random.beta(friends_num, friends_num.mean(), n)\n",
    "\n",
    "age= np.random.normal(12 + 0.001*friends_num - 4*family_reserve, 2)\n",
    "age = (age > 4).astype(float) * internexp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gender = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "diploma =  np.random.binomial(1, 0.5, n)\n",
    "\n",
    "Entrepreneurial_success_rate= pd.DataFrame(dict(diploma=diploma,\n",
    "                         internexp=internexp,\n",
    "                         age=age,\n",
    "                         gender=gender,\n",
    "                         friends_num=friends_num,\n",
    "                         family_reserve=family_reserve))\n",
    "\n",
    "Entrepreneurial_success_rate.to_csv(\"collections_email.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3dc2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c8f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\zgd_0\\anaconda3\\lib\\site-packages (0.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bac5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x217ebfd2a00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dabd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367cc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c15881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33f0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfa897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [00:02<00:00, 166.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 0 # number of covariates used in the DGP\n",
    "Nrange = range(10,1000,2) # loop over N values\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e059b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:02<00:00, 822.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:28<00:00, 69.21it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e40fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.0006608664320117557, RMSE=0.19802412822446994, size=0.0535\n",
      "N=1000: bias=-0.0017727279055219905, RMSE=0.06244164684044309, size=0.046\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cccad9",
   "metadata": {},
   "source": [
    "# 1(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf4787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(26)\n",
    "n = 700\n",
    "internexp= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "friends_num= np.random.gamma(1, 30, n)\n",
    "family_reserve = np.random.beta(friends_num, friends_num.mean(), n)\n",
    "\n",
    "age= np.random.normal(12 + 0.001*friends_num - 4*family_reserve, 2)\n",
    "age = (age > 4).astype(float) * internexp\n",
    "policysupport= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "\n",
    "gender = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "diploma =  np.random.binomial(1, 0.5, n)\n",
    "\n",
    "Entrepreneurial_success_rate= pd.DataFrame(dict(diploma=diploma,\n",
    "                         internexp=internexp,\n",
    "                         age=age,\n",
    "                         gender=gender,\n",
    "                         friends_num=friends_num,\n",
    "                         policysupport= policysupport,\n",
    "                         family_reserve=family_reserve))#1 million is the unit\n",
    "\n",
    "Entrepreneurial_success_rate.to_csv(\"collections_email.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca412ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213aec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1545269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34132e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 1 # number of covariates used in the DGP\n",
    "Nrange = range(10,1000,2) # loop over N values\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e662494",
   "metadata": {},
   "outputs": [],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3cf9c",
   "metadata": {},
   "source": [
    "# 2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c3d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(26)\n",
    "n = 700\n",
    "internexp= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "recommend_num= np.random.gamma(1, 30, n)\n",
    "family_reserve = np.random.beta(friends_num, recommend_num.mean(), n)\n",
    "\n",
    "age= np.random.normal(12 + 0.001*recommend_num - 4*family_reserve, 2)\n",
    "age = (age > 4).astype(float) * internexp\n",
    "\n",
    "\n",
    "\n",
    "gender = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "diploma =  np.random.binomial(1, 0.5, n)\n",
    "\n",
    "Admission_rate_fpr_colledge= pd.DataFrame(dict(diploma=diploma,\n",
    "                         internexp=internexp,\n",
    "                         age=age,\n",
    "                         gender=gender,\n",
    "                         recommend_num=recommend_num,\n",
    "                         family_reserve=family_reserve))#1 million is the unit\n",
    "\n",
    "Admission_rate_fpr_colledge.to_csv(\"collections_email.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ca7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d26349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b21770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9f909",
   "metadata": {},
   "outputs": [],
   "source": [
    " tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 0 # number of covariates used in the DGP\n",
    "Nrange = range(10,1000,2) # loop over N values\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab64f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6e938",
   "metadata": {},
   "source": [
    "# 2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0492e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(26)\n",
    "n = 700\n",
    "internexp= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "recommend_num= np.random.gamma(1, 30, n)\n",
    "family_reserve = np.random.beta(friends_num, recommend_num.mean(), n)\n",
    "\n",
    "age= np.random.normal(12 + 0.001*recommend_num - 4*family_reserve, 2)\n",
    "age = (age > 4).astype(float) * internexp\n",
    "\n",
    "beautylevel=np.random.binomial(1, 0.5, n)\n",
    "\n",
    "gender = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "diploma =  np.random.binomial(1, 0.5, n)\n",
    "\n",
    "Admission_rate_fpr_colledge= pd.DataFrame(dict(diploma=diploma,\n",
    "                         internexp=internexp,\n",
    "                         age=age,\n",
    "                         gender=gender,\n",
    "                         recommend_num=recommend_num,\n",
    "                         Beautylevel=beautylevel,\n",
    "                         family_reserve=family_reserve))#1 million is the unit\n",
    "\n",
    "Admission_rate_fpr_colledge.to_csv(\"collections_email.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f9ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be4d86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x217f2596100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828e69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "effbefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07393141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b562535a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "    else:\n",
    "        conf_mult=1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf74e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [00:02<00:00, 173.13it/s]\n"
     ]
    }
   ],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=True\n",
    "p = 10\n",
    "p0 = 0 # number of covariates used in the DGP\n",
    "Nrange = range(10,1000,2) # loop over N values\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c718c46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:02<00:00, 838.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:29<00:00, 67.49it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05df36af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.0024249453363948802, RMSE=0.22891683210469146, size=0.0575\n",
      "N=1000: bias=0.001686121950189373, RMSE=0.07237276968408557, size=0.05\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db890ebd",
   "metadata": {},
   "source": [
    "# 3(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0156012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(26)\n",
    "n = 500\n",
    "internexp= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "friends_num= np.random.gamma(1, 30, n)\n",
    "family_reserve = np.random.beta(friends_num, friends_num.mean(), n)\n",
    "\n",
    "age= np.random.normal(12 + 0.001*friends_num - 4*family_reserve, 2)\n",
    "age = (age > 4).astype(float) * internexp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gender = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "diploma =  np.random.binomial(1, 0.5, n)\n",
    "\n",
    "marrage_success_rate= pd.DataFrame(dict(diploma=diploma,\n",
    "                         internexp=internexp,\n",
    "                         age=age,\n",
    "                         gender=gender,\n",
    "                         friends_num=friends_num,\n",
    "                         family_reserve=family_reserve))\n",
    "\n",
    "marrage_success_rate.to_csv(\"collections_email.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76194af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a67b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22926f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 0 # number of covariates used in the DGP\n",
    "Nrange = range(10,1000,2) # loop over N values\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e928f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5be0de",
   "metadata": {},
   "source": [
    "# 3(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b9f500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(26)\n",
    "n = 500\n",
    "internexp= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "friends_num= np.random.gamma(1, 30, n)\n",
    "family_reserve = np.random.beta(friends_num, friends_num.mean(), n)\n",
    "\n",
    "age= np.random.normal(12 + 0.001*friends_num - 4*family_reserve, 2)\n",
    "age = (age > 4).astype(float) * internexp\n",
    "\n",
    "\n",
    "introducer= np.random.binomial(1, 0.5, n)\n",
    "\n",
    "\n",
    "gender = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "diploma =  np.random.binomial(1, 0.5, n)\n",
    "\n",
    "marrage_success_rate= pd.DataFrame(dict(diploma=diploma,\n",
    "                         internexp=internexp,\n",
    "                         age=age,\n",
    "                         gender=gender,\n",
    "                         friends_num=friends_num,\n",
    "                         introducer=introducer,\n",
    "                         family_reserve=family_reserve))\n",
    "\n",
    "marrage_success_rate.to_csv(\"collections_email.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c63d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f459ad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x217f1efed00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "026c7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce2a8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ecfb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c05c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8b57cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [00:03<00:00, 164.73it/s]\n"
     ]
    }
   ],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 0 # number of covariates used in the DGP\n",
    "Nrange = range(10,1000,2) # loop over N values\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83f64042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:02<00:00, 789.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:29<00:00, 67.04it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76b08fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.0023796628482306544, RMSE=0.1926629997896674, size=0.049\n",
      "N=1000: bias=0.0004776398764149242, RMSE=0.06371849989018771, size=0.052\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c53118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
